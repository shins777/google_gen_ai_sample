{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"10QiVBSVRSu69Uhr9OpzX3-8CFvMdG4EZ","timestamp":1717906152865},{"file_id":"1btZCldJxz-DFxshEjVFBksH3cFZ7ZWzY","timestamp":1717886695950}],"toc_visible":true,"authorship_tag":"ABX9TyML7kaSdVLZg/3JEQzMUllb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Disclaimer & Copyright\n","\n","Copyright 2024 Forusone : shins777@gmail.com\n","\n","Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n","\n","https://www.apache.org/licenses/LICENSE-2.0\n","\n","Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."],"metadata":{"id":"OQJknXG7C9Dq"}},{"cell_type":"markdown","source":["# Vector DB - BigQuery using Custom Embedding model.\n","\n","* This notebook explains how to use BigQuery as a Vector database using Custom Embedding model.\n","* Reference\n","  * https://cloud.google.com/bigquery/docs/vector-search-intro?hl=ko\n","  * https://python.langchain.com/docs/integrations/vectorstores/google_bigquery_vector_search\n","  * https://api.python.langchain.com/en/stable/embeddings/langchain_core.embeddings.Embeddings.html#langchain_core.embeddings.Embeddings\n","\n","* Data reference\n","  * https://www.data.go.kr/data/15069932/fileData.do"],"metadata":{"id":"zB93wBDYDCPI"}},{"cell_type":"markdown","source":["# Configuration\n","## Install python packages\n","* Vertex AI SDK for Python\n","  * https://cloud.google.com/python/docs/reference/aiplatform/latest"],"metadata":{"id":"Vuxu3iRDDtcl"}},{"cell_type":"code","source":["%pip install --upgrade --quiet google-cloud-aiplatform"],"metadata":{"id":"wevZD-jnD-ft"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%pip install --upgrade --quiet langchain langchain-community"],"metadata":{"id":"XIPyCs8DNZwD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%pip install --upgrade --quiet sentence_transformers"],"metadata":{"id":"G6PFT8ZFNc7k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from IPython.display import display, Markdown"],"metadata":{"id":"-nhL4T2sKsdp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Authentication to access to the GCP & Google drive\n","\n","* Use OAuth to access the GCP environment.\n"," * Refer to the authentication methods in GCP : https://cloud.google.com/docs/authentication?hl=ko"],"metadata":{"id":"tCVttGUsEzgj"}},{"cell_type":"code","source":["#  For only colab to authenticate to get an access to the GCP.\n","import sys\n","\n","if \"google.colab\" in sys.modules:\n","    from google.colab import auth\n","    auth.authenticate_user()"],"metadata":{"id":"AJuo1g4bE3-x"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Mount to the google drive to access the .ipynb files in the repository.\n","\n"],"metadata":{"id":"mQoisCsVE6LM"}},{"cell_type":"code","source":["# To access contents in Google drive\n","\n","if \"google.colab\" in sys.modules:\n","  from google.colab import drive\n","  drive.mount('/content/drive')"],"metadata":{"id":"ZhluEayrE_Io"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Execute the example\n","## Set the environment on GCP Project\n","* Configure project information\n","  * Model name : LLM model name : https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\n","  * Project Id : prodect id in GCP\n","  * Region : region name in GCP"],"metadata":{"id":"ey_Bv55hIblt"}},{"cell_type":"code","source":["MODEL_NAME=\"gemini-1.5-flash\"\n","PROJECT_ID=\"ai-hangsik\"\n","REGION=\"asia-northeast3\""],"metadata":{"id":"XJwhurOUHIG-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Vertex AI initialization\n","Configure Vertex AI and access to the foundation model.\n","* Vertex AI initialization : aiplatform.init(..)\n","  * https://cloud.google.com/python/docs/reference/aiplatform/latest#initialization"],"metadata":{"id":"Xk3nZQQhIiom"}},{"cell_type":"code","source":["import vertexai\n","from vertexai.preview.generative_models import GenerativeModel, Part\n","import vertexai.preview.generative_models as generative_models\n","\n","# Initalizate the current vertex AI execution environment.\n","vertexai.init(project=PROJECT_ID, location=REGION)\n","\n","# Access to the generative model.\n","model = GenerativeModel(MODEL_NAME)"],"metadata":{"id":"HZ6WeWz4HIEW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Custom Embedding\n","* To use Langchain function for custom embedding, you need to implement Ebeddings interface like the following steps.\n","\n","* Refer to Ebeddings interface implementation : https://api.python.langchain.com/en/stable/embeddings/langchain_core.embeddings.Embeddings.html#langchain_core.embeddings.Embeddings\n","\n","* Need to implement the following two functions\n","  * abstract embed_documents(texts: List[str]) → List[List[float]]\n","  * embed_query(text: str) → List[float]"],"metadata":{"id":"6tMfG1l_OajX"}},{"cell_type":"code","source":["from langchain_core.embeddings import Embeddings\n","from typing import List\n","\n","from sentence_transformers import SentenceTransformer\n","\n","class Custom_Embedding(Embeddings):\n","\n","  model = None\n","\n","  def __init__(self, model_name: str):\n","    self.model = SentenceTransformer(model_name)\n","\n","  def embed_documents(self, texts: List[str]) -> List[List[float]]:\n","    embeddings = self.model.encode(texts)\n","    return embeddings.tolist()\n","\n","  def embed_query(self, text: str) -> List[float]:\n","    embeddings = self.model.encode([text])\n","    return embeddings.tolist()[0]"],"metadata":{"id":"9_xF0-7dOZ92"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Custom Embeddings model\n","* Use a model that was verified in Hugging face\n","* Use your model for the specific purpose if you have your model.\n","\n","  * https://huggingface.co/snunlp/KR-SBERT-V40K-klueNLI-augSTS\n","  * https://huggingface.co/sentence-transformers/stsb-xlm-r-multilingual"],"metadata":{"id":"-0s-StNKPASw"}},{"cell_type":"code","source":["EBEDDING_MODEL = \"snunlp/KR-SBERT-V40K-klueNLI-augSTS\"\n","embedding = Custom_Embedding(EBEDDING_MODEL)"],"metadata":{"id":"h_aN5NCPO9-Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Create dataset and table in BigQuery"],"metadata":{"id":"PGSC5w3CYUso"}},{"cell_type":"code","source":["from google.cloud import bigquery\n","\n","DATASET = \"vector_db_custom\"\n","TABLE = \"vector_table_custom\"\n","\n","client = bigquery.Client(project=PROJECT_ID, location=REGION)\n","client.create_dataset(dataset=DATASET, exists_ok=True)\n"],"metadata":{"id":"Z414lc6_PaUB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Vector Search environment"],"metadata":{"id":"wGS8rX5uYQvl"}},{"cell_type":"code","source":["\n","from langchain.vectorstores.utils import DistanceStrategy\n","from langchain_community.vectorstores import BigQueryVectorSearch\n","\n","table = BigQueryVectorSearch(\n","    project_id=PROJECT_ID,\n","    dataset_name=DATASET,\n","    table_name=TABLE,\n","    location=REGION,\n","    embedding=embedding,\n","\n","    #https://api.python.langchain.com/en/stable/vectorstores/langchain_community.vectorstores.utils.DistanceStrategy.html#langchain_community.vectorstores.utils.DistanceStrategy\n","    distance_strategy=DistanceStrategy.COSINE\n","\n",")"],"metadata":{"id":"PjK8BJokP016"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Read the text data that will be vectorized."],"metadata":{"id":"-d2-ATeUYDSu"}},{"cell_type":"code","source":["import pandas as pd\n","\n","file_path = '/content/drive/MyDrive/projects/google_gen_ai_sample/contents/text/legal_terminology.csv'\n","\n","legal_terms = pd.read_csv(file_path,sep=\",\", encoding='utf-8-sig')\n","legal_terms"],"metadata":{"id":"J7R6aWz9QDT6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Embedding and store the vector data into BigQuery"],"metadata":{"id":"qWCfaUo2X9d7"}},{"cell_type":"code","source":["import json\n","\n","all_texts = legal_terms['설명'].to_list()\n","metadatas = [ {'Term': row['용어명'] } for idx, row in legal_terms.iterrows()]\n","table.add_texts(all_texts, metadatas=metadatas)\n","# table.add_texts(all_texts)\n"],"metadata":{"id":"frsMjItVQeKz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Vector Search\n","### Search with string"],"metadata":{"id":"mU2MaFAPSH1p"}},{"cell_type":"code","source":["import time\n","s = time.time()\n","query = \"가등기권리자란?\"\n","\n","docs = table.similarity_search(query, k=5)\n","for doc in docs:\n","  print(f\" {doc.metadata['Term']} - {doc.page_content}\" )\n","\n","e = time.time() - s\n","print(e)"],"metadata":{"id":"sq--noGWQeH7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Search with vector\n","* https://api.python.langchain.com/en/stable/vectorstores/langchain_community.vectorstores.bigquery_vector_search.BigQueryVectorSearch.html#langchain_community.vectorstores.bigquery_vector_search.BigQueryVectorSearch.similarity_search"],"metadata":{"id":"-JqLPbsLSDx7"}},{"cell_type":"code","source":["query_vector = embedding.embed_query(query)\n","docs = table.similarity_search_by_vector(query_vector, k=5)\n","for doc in docs:\n","  print(f\" {doc.metadata['Term']} - {doc.page_content}\" )"],"metadata":{"id":"tBtC8kNgQeFn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Search with relevant score"],"metadata":{"id":"9-_rQjGuR2sd"}},{"cell_type":"code","source":["tuples = table.similarity_search_with_relevance_scores(query, k=5)\n","context ={}\n","\n","for tp in tuples:\n","    context[tp[1]] = tp[0].metadata[\"Term\"] + \" : \" + tp[0].page_content\n","context"],"metadata":{"id":"mc42bnW4REje"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Max marginal relavant search\n","* https://api.python.langchain.com/en/stable/vectorstores/langchain_community.vectorstores.bigquery_vector_search.BigQueryVectorSearch.html#langchain_community.vectorstores.bigquery_vector_search.BigQueryVectorSearch.max_marginal_relevance_search"],"metadata":{"id":"X4fYG2L3R7PC"}},{"cell_type":"code","source":["docs = table.max_marginal_relevance_search(query= query,\n","                                           k=5,\n","                                           fetch_k = 30,\n","                                           lambda_mult = 0.5,\n","                                           brute_force = True\n","                                           )\n","for doc in docs:\n","  print(doc.page_content)"],"metadata":{"id":"O4bH_HC5Qd9p"},"execution_count":null,"outputs":[]}]}