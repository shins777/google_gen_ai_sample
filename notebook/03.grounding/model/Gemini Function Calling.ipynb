{"cells":[{"cell_type":"markdown","metadata":{"id":"Vo6hw1koPHTL"},"source":["Copyright 2024 - Forusone : shins777@gmail.com\n","\n","Licensed under the Apache License, Version 2.0 (the \"License\");\n","you may not use this file except in compliance with the License.\n","You may obtain a copy of the License at\n","\n","   https://www.apache.org/licenses/LICENSE-2.0\n","\n","Unless required by applicable law or agreed to in writing, software\n","distributed under the License is distributed on an \"AS IS\" BASIS,\n","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","See the License for the specific language governing permissions and\n","limitations under the License."]},{"cell_type":"markdown","metadata":{"id":"oAmrBjzC-weK"},"source":["# Gemini Pro - Function call\n","\n","* This notebook explains how to use function calling feature in Gemini.\n","\n","* Refer to https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/function-calling"]},{"cell_type":"markdown","metadata":{"id":"G-cUpjAMUQZ9"},"source":["# Configuration\n","## Install python packages\n","* Vertex AI SDK for Python\n","  * https://cloud.google.com/python/docs/reference/aiplatform/latest\n"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":38540,"status":"ok","timestamp":1718012461727,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"},"user_tz":-540},"id":"SWV1C2BLrkGR","colab":{"base_uri":"https://localhost:8080/"},"outputId":"47c6917c-5fc2-4ebe-9314-57d371443427"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["%pip install --upgrade --quiet google-cloud-aiplatform"]},{"cell_type":"code","source":["from IPython.display import display, Markdown"],"metadata":{"id":"MqSTf34-WHuK","executionInfo":{"status":"ok","timestamp":1718012463750,"user_tz":-540,"elapsed":339,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kjgasEpKBgMC"},"source":["## Authentication to access to the GCP & Google drive\n","\n","* Use OAuth to access the GCP environment.\n"," * Refer to the authentication methods in GCP : https://cloud.google.com/docs/authentication?hl=ko"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":14782,"status":"ok","timestamp":1718012481636,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"},"user_tz":-540},"id":"XHUPlLRgNBgS"},"outputs":[],"source":["#  For only colab to authenticate to get an access to the GCP.\n","import sys\n","\n","if \"google.colab\" in sys.modules:\n","    from google.colab import auth\n","    auth.authenticate_user()"]},{"cell_type":"markdown","source":["* Mount to the google drive to access the .ipynb files in the repository."],"metadata":{"id":"NYcRKKclT3rf"}},{"cell_type":"code","source":["# To access contents in Google drive\n","\n","if \"google.colab\" in sys.modules:\n","  from google.colab import drive\n","  drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2pOgmGbJT2TG","executionInfo":{"status":"ok","timestamp":1718012531519,"user_tz":-540,"elapsed":49885,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"cb75fca4-9a91-420e-e8ba-60040bce51ad"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"DGDQkGBB4_UE"},"source":["# Execute the example\n","## Set the environment on GCP Project\n","* Configure project information\n","  * Model name : LLM model name : https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\n","  * Project Id : prodect id in GCP\n","  * Region : region name in GCP"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":349,"status":"ok","timestamp":1718021161473,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"},"user_tz":-540},"id":"k7ZEsQhjo7Tz"},"outputs":[],"source":["MODEL_NAME=\"gemini-1.5-flash\"\n","PROJECT_ID=\"ai-hangsik\"\n","REGION=\"asia-northeast3\""]},{"cell_type":"markdown","source":["### Vertex AI initialization\n","Configure Vertex AI and access to the foundation model.\n","* Vertex AI initialization : aiplatform.init(..)\n","  * https://cloud.google.com/python/docs/reference/aiplatform/latest#initialization"],"metadata":{"id":"3Dtv_t6GVV87"}},{"cell_type":"code","source":["import vertexai\n","from vertexai.generative_models import GenerativeModel, Part, Tool\n","import vertexai.generative_models as generative_models\n","\n","# Grounding service is still in preview.\n","from vertexai.preview.generative_models import grounding\n","\n","# Initalizate the current vertex AI execution environment.\n","vertexai.init(project=PROJECT_ID, location=REGION)\n","\n","# Access to the generative model.\n","model = GenerativeModel(MODEL_NAME)"],"metadata":{"id":"ipMgcPZnVYlh","executionInfo":{"status":"ok","timestamp":1718021168341,"user_tz":-540,"elapsed":3806,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## Function to be called by LLM\n","* The following function will be called by LLM if the condition is satisfied."],"metadata":{"id":"EDfQb4vxCtUj"}},{"cell_type":"code","source":["def get_stock_price(ticker:str) ->str:\n","  \"\"\"\n","  The ticker passed to Arg is the value found by LLM.\n","  If you say, Tell me the price of Google stock, the argument passed to arg here can be GOOG or GOOGL.\n","\n","  ticker : str\n","  Stock ticker\n","\n","  return : str\n","  Stock price\n","  \"\"\"\n","\n","  print(f\"Request ticker : {ticker}\")\n","\n","  return \"Stock price is 445.55\"\n"],"metadata":{"id":"gyGJ1QNYCsed","executionInfo":{"status":"ok","timestamp":1718021424902,"user_tz":-540,"elapsed":2,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["## Function including Gemini function calling logic."],"metadata":{"id":"3dEWbqo3EVKa"}},{"cell_type":"code","source":["from vertexai.generative_models import FunctionDeclaration\n","from vertexai.generative_models import GenerativeModel, Part, Tool\n","\n","def function_call(prompt:str)->str:\n","\n","  # Tools\n","  tools = Tool(function_declarations=[\n","      FunctionDeclaration(\n","          name=\"get_stock_price\",\n","          description=\"Get the current stock price of a given company\",\n","          parameters={\n","              \"type\": \"object\",\n","              \"properties\": {\n","                  \"ticker\": {\n","                      \"type\": \"string\",\n","                      \"description\": \"Stock ticker symbol\"\n","                  }\n","              }\n","          },\n","      )\n","  ])\n","\n","  # Model Initialization\n","  model = GenerativeModel(\"gemini-pro\",\n","                          generation_config={\"temperature\": 0},\n","                          tools=[tools])\n","\n","  chat = model.start_chat()\n","\n","  # Send a prompt to the chat\n","  response = chat.send_message(prompt)\n","  function_call = response.candidates[0].content.parts[0].function_call\n","\n","  function_handlers = {\n","      \"get_stock_price\": get_stock_price,\n","  }\n","\n","  if function_call.name in function_handlers:\n","      function_name = function_call.name\n","      chat_response = \"\"\n","\n","      args = {key: value for key, value in function_call.args.items()}\n","\n","      if args:\n","          function_response = function_handlers[function_name](args)\n","\n","          part_data = Part.from_function_response(\n","                  name=function_name,\n","                  response={\n","                      \"content\": function_response,\n","                  }\n","          )\n","\n","          cal_eq = part_data.to_dict()['function_response']['response']['content']\n","\n","          response = chat.send_message(part_data,)\n","          chat_response = response.candidates[0].content.parts[0].text\n","\n","          print(f\"Response with function calling: {chat_response}\")\n","          return chat_response\n","      else:\n","          print(\"No arguments found for the function.\")\n","          return \"Please let me know the name of company that you want to know the stock price\"\n","  else:\n","      print(\"Response without function calling\")\n","      return response.text\n"],"metadata":{"id":"TUFi7L8lCscV","executionInfo":{"status":"ok","timestamp":1718021555847,"user_tz":-540,"elapsed":351,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["## Execute the example"],"metadata":{"id":"t0c1QPxxEfis"}},{"cell_type":"markdown","source":["### Response with a prompt that becomes a function call\n","* In this case, if the LLM determines a prompt that a currently registered function needs to be called when considering contents, the function could be called, the LLM receives the result, creates the corresponding value, and returns it."],"metadata":{"id":"lN1O80DrEurd"}},{"cell_type":"code","source":["prompt = \"How much is the Google's stock price?\"\n","function_call(prompt)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":74},"id":"qM-ce3I0Csak","executionInfo":{"status":"ok","timestamp":1718021561220,"user_tz":-540,"elapsed":3690,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"7ff7c4cb-8ef7-4793-98b1-36dd90ac4ab3"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Request ticker : {'ticker': 'GOOG'}\n","Response with function calling: The current stock price of Google is 445.55.\n"]},{"output_type":"execute_result","data":{"text/plain":["'The current stock price of Google is 445.55.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["### Reponse with a prompt where the function call is not called\n","* In this case, the LLM determines the contents of the prompt and there is no function to be called."],"metadata":{"id":"Az7h-Zx7En_7"}},{"cell_type":"code","source":["prompt = \"How is the weather in Seoul?\"\n","function_call(prompt)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":57},"id":"OQQobgHTCsXE","executionInfo":{"status":"ok","timestamp":1718021570374,"user_tz":-540,"elapsed":2413,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"0e91db7e-8f0d-4939-b48f-4ef1bd99d52c"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Response without function calling\n"]},{"output_type":"execute_result","data":{"text/plain":["'I am sorry, I cannot fulfill this request. The available tools lack the desired functionality.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":13}]}],"metadata":{"colab":{"provenance":[{"file_id":"1ysth26WNEZ89ceoUWyiBNEhJhAKPzZzD","timestamp":1707791310414},{"file_id":"1SMBsO1Oo1C_iwdVlaPxa-nHarsr1LlXw","timestamp":1707790104224},{"file_id":"12QOQwx4nCfn-TVBJz482kmzE9AO7LOEa","timestamp":1706083956041},{"file_id":"1SEMv5rLuJzrFmgv6ijM-a6frQK6vJh-F","timestamp":1685622927692},{"file_id":"17KvSE1Jozr-l8MPgV0qc96RqjDGib6EG","timestamp":1683740067510},{"file_id":"/v2/external/notebooks/snippets/bigquery.ipynb","timestamp":1674946081821}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.2"}},"nbformat":4,"nbformat_minor":0}