{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1btZCldJxz-DFxshEjVFBksH3cFZ7ZWzY","timestamp":1717886695950}],"toc_visible":true,"mount_file_id":"14PLn0kSK38X_Gb34nVhWJ-8Oln2Ap-S8","authorship_tag":"ABX9TyM1XxhOIlPemPvV49wxzUlJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Disclaimer & Copyright\n","\n","Copyright 2024 Forusone : shins777@gmail.com\n","\n","Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n","\n","https://www.apache.org/licenses/LICENSE-2.0\n","\n","Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."],"metadata":{"id":"OQJknXG7C9Dq"}},{"cell_type":"markdown","source":["# Gemini - Fact finding from a pdf file.\n","* This notebook explains how to use Gemini to understand PDF files in the multimodality features of Gemini.\n","* Mainly focusing on finding some facts that existed in the various objects such as in text, image, and graph.\n","* Refer to the link for more information about the Gemini\n"," * ***https://cloud.google.com/vertex-ai/generative-ai/docs/learn/overview***"],"metadata":{"id":"zB93wBDYDCPI"}},{"cell_type":"markdown","source":["# Configuration\n","## Install python packages\n","* Vertex AI SDK for Python\n","  * https://cloud.google.com/python/docs/reference/aiplatform/latest"],"metadata":{"id":"Vuxu3iRDDtcl"}},{"cell_type":"code","source":["%pip install --upgrade --quiet google-cloud-aiplatform"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wevZD-jnD-ft","executionInfo":{"status":"ok","timestamp":1718427644880,"user_tz":-540,"elapsed":27641,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"b2e7ed37-a481-454a-d9ef-db8b49faae76"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/5.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/5.1 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/5.1 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m3.8/5.1 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["from IPython.display import display, Markdown"],"metadata":{"id":"-nhL4T2sKsdp","executionInfo":{"status":"ok","timestamp":1718427644880,"user_tz":-540,"elapsed":5,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## Authentication to access to the GCP & Google drive\n","\n","* Use OAuth to access the GCP environment.\n"," * Refer to the authentication methods in GCP : https://cloud.google.com/docs/authentication?hl=ko"],"metadata":{"id":"tCVttGUsEzgj"}},{"cell_type":"code","source":["#  For only colab to authenticate to get an access to the GCP.\n","import sys\n","\n","if \"google.colab\" in sys.modules:\n","    from google.colab import auth\n","    auth.authenticate_user()"],"metadata":{"id":"AJuo1g4bE3-x","executionInfo":{"status":"ok","timestamp":1718427659888,"user_tz":-540,"elapsed":15012,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["* Mount to the google drive to access the .ipynb files in the repository.\n","\n"],"metadata":{"id":"mQoisCsVE6LM"}},{"cell_type":"code","source":["# To access contents in Google drive\n","\n","if \"google.colab\" in sys.modules:\n","  from google.colab import drive\n","  drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZhluEayrE_Io","executionInfo":{"status":"ok","timestamp":1718427682830,"user_tz":-540,"elapsed":22946,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"e920d4ce-8175-449e-af70-b117d31fb029"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# Execute the example\n","## Set the environment on GCP Project\n","* Configure project information\n","  * Model name : LLM model name : https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\n","  * Project Id : prodect id in GCP\n","  * Region : region name in GCP"],"metadata":{"id":"ey_Bv55hIblt"}},{"cell_type":"code","source":["MODEL_NAME=\"gemini-1.5-flash\"\n","PROJECT_ID=\"ai-hangsik\"\n","REGION=\"asia-northeast3\""],"metadata":{"id":"XJwhurOUHIG-","executionInfo":{"status":"ok","timestamp":1718427682830,"user_tz":-540,"elapsed":4,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["### Vertex AI initialization\n","Configure Vertex AI and access to the foundation model.\n","* Vertex AI initialization : aiplatform.init(..)\n","  * https://cloud.google.com/python/docs/reference/aiplatform/latest#initialization"],"metadata":{"id":"Xk3nZQQhIiom"}},{"cell_type":"code","source":["import vertexai\n","from vertexai.preview.generative_models import GenerativeModel, Part\n","import vertexai.preview.generative_models as generative_models\n","\n","# Initalizate the current vertex AI execution environment.\n","vertexai.init(project=PROJECT_ID, location=REGION)\n","\n","# Access to the generative model.\n","model = GenerativeModel(MODEL_NAME)"],"metadata":{"id":"HZ6WeWz4HIEW","executionInfo":{"status":"ok","timestamp":1718427686692,"user_tz":-540,"elapsed":3865,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["Encoding function for multimodality"],"metadata":{"id":"2QV1mbbBJRGf"}},{"cell_type":"code","source":["import base64\n","\n","def get_encoded_content(location_type, location, mime_type ):\n","  \"\"\"\n","  Get the encoded content object.\n","\n","  location_type :\n","    The type of the location. ( local or GCS )\n","  location :\n","    The file location of the content.\n","  mime_type :\n","    The mime type of the content.\n","\n","  Returns:\n","    The encoded content object.\n","\n","  \"\"\"\n","\n","  content_obj = None\n","\n","  if location_type == \"local\":\n","    with open(location, 'rb') as f:\n","      raw_obj = base64.b64encode(f.read()).decode('utf-8')\n","      content_obj = Part.from_data(data=base64.b64decode(raw_obj), mime_type=mime_type)\n","\n","  elif location_type == \"GCS\":\n","        content_obj = Part.from_uri(location, mime_type=mime_type)\n","  else:\n","    raise ValueError(\"Invalid location type.\")\n","\n","  return content_obj"],"metadata":{"id":"ySzNqqGmHIBm","executionInfo":{"status":"ok","timestamp":1718427686692,"user_tz":-540,"elapsed":4,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["### Function to get the response"],"metadata":{"id":"r4NbkJ4HJYBB"}},{"cell_type":"code","source":["def generate(content_obj, query:str):\n","    \"\"\"\n","    Generate a response from the model.\n","\n","    content_obj :\n","      encoded object being analyzed in the process\n","    query :\n","      query to be sent to the model\n","\n","    Returns:\n","      The generated response.\n","\n","    \"\"\"\n","\n","    # Set model parameter : https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/send-multimodal-prompts#set_model_parameters\n","    generation_config = {\n","        \"max_output_tokens\": 8192,\n","        \"temperature\": 1,\n","        \"top_p\": 0.95,\n","    }\n","\n","    # Configure satey setting : https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-attributes\n","    # Refer to the link to remove : https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-attributes#how_to_remove_automated_response_blocking_for_select_safety_attributes\n","    safety_settings = {\n","        generative_models.HarmCategory.HARM_CATEGORY_HATE_SPEECH: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n","        generative_models.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n","        generative_models.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n","        generative_models.HarmCategory.HARM_CATEGORY_HARASSMENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n","    }\n","\n","    responses = model.generate_content(\n","        [content_obj, query],\n","        generation_config=generation_config,\n","        safety_settings=safety_settings,\n","        stream=False,\n","    )\n","\n","    return responses.text"],"metadata":{"id":"sMaCwPVGJXX6","executionInfo":{"status":"ok","timestamp":1718427686692,"user_tz":-540,"elapsed":4,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["## Run example"],"metadata":{"id":"bGdT-2WHJuXf"}},{"cell_type":"code","source":["from time import perf_counter\n","\n","t1_start = perf_counter()\n","\n","# When using local storage for the file location.\n","location_type = \"local\"\n","mime_type = \"application/pdf\"\n","\n","repository_root = \"/content/drive/MyDrive/projects/google_gen_ai_sample/\"\n","file_path = \"contents/pdfs/the-state-of-ai-in-early-2024-final.pdf\"\n","location = repository_root + file_path\n","\n","content_obj = get_encoded_content(location_type, location, mime_type )\n","\n","prompt = \"\"\"\n","You are a helpful assistant that summarizes a pdf file.\n","Answer the following questions from understanding the pdf file.\n","\n","1. How much percentage of the use of generative AI in 2024 was changed compared to 2023 from the graph?\n","2. Which function(department) is the most commonly using the generative AI in 2024? and how much percentage of the use is?\n","3. Why Energy and materials sector is the most commonly using the generative AI in 2024? please infer the reason by considering the characteristic of industry.\n","\n","\"\"\"\n","\n","outcome = generate(content_obj, prompt)\n","\n","t1_end  = perf_counter()\n","print(f\"Time : {t1_end - t1_start} seconds\\n\\n\")\n","\n","display(Markdown(outcome))\n"],"metadata":{"id":"-0Lpj5TaJXVQ","colab":{"base_uri":"https://localhost:8080/","height":271},"executionInfo":{"status":"ok","timestamp":1718427699423,"user_tz":-540,"elapsed":12734,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"5d97128b-81fd-4e65-8fde-e893635f28f1"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Time : 12.668433785000047 seconds\n","\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"Here are the answers to your questions:\n\n1.  The percentage of respondents who reported using generative AI in 2024 was **65 percent**,  nearly **double** the percentage from 2023. \n\n2.  The most commonly reported use of generative AI in 2024 was in **marketing and sales** with **34 percent** of respondents using it. \n\n3.  The article does not explicitly state why the Energy and materials sector is the most commonly using generative AI in 2024, but it is possible to infer some reasons based on the characteristics of this industry. The energy and materials sector is often highly data-driven, involving complex operations and processes that can be analyzed using AI to improve efficiency and optimize resource allocation. Given this, the industry is likely to see more value from generative AI applications in areas like product and service development, supply chain optimization, and risk management, which could explain its high adoption rate.  It's also possible that energy and materials companies are more willing to experiment with new AI tools and invest in developing proprietary models.\n"},"metadata":{}}]}]}